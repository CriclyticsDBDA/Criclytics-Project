{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ast\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark import SQLContext , SparkContext\n",
    "from pyspark.sql.session import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=example, master=local) created by __init__ at <ipython-input-1-696c9701050e>:4 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f1cc6e883073>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'local'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'example'\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# if using locally\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msqlContext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSQLContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \"\"\"\n\u001b[0;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callsite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfirst_spark_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mCallSite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    297\u001b[0m                         \u001b[1;34m\" created by %s at %s:%s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m                         % (currentAppName, currentMaster,\n\u001b[1;32m--> 299\u001b[1;33m                             callsite.function, callsite.file, callsite.linenum))\n\u001b[0m\u001b[0;32m    300\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m                     \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=example, master=local) created by __init__ at <ipython-input-1-696c9701050e>:4 "
     ]
    }
   ],
   "source": [
    "sc = SparkContext('local','example')  # if using locally\n",
    "sqlContext = SQLContext(sc)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2698: DtypeWarning: Columns (15,16,26,33,37,38,39,43,44,46,48,49,50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Employee_rdd = sc.textFile(\"final_all_3.1.csv\").map(lambda line: line.split(\",\"))\n",
    "#Employee_df = Employee_rdd.toDF(['Unnamed: 0','Unnamed: 0.1','Unnamed: 0.1.1','batsman','bowler','date','extras.byes','extras.legbyes','extras.noballs','extras.penalty','extras.s','extras.wides','index_all','non_striker','replacements.match','replacements.role','runs.batsman','runs.extras','runs.non_boundary','runs.total','team','wicket','wicket.fielders','wicket.kind','wicket.player_out','info.bowl_out','info.city','info.competition','info.dates','info.gender','info.match_type','info.neutral_venue','info.outcome.bowl_out','info.outcome.by.innings','info.outcome.by.runs','info.outcome.by.wickets','info.outcome.eliminator','info.outcome.method','info.outcome.result','info.outcome.winner','info.overs','info.player_of_match','info.supersubs.Australia','info.supersubs.Bangladesh','info.supersubs.India','info.supersubs.New Zealand','info.supersubs.Pakistan','info.supersubs.South Africa','info.supersubs.Sri Lanka','info.supersubs.West Indies','info.teams','info.toss.decision','info.toss.winner','info.umpires','info.venue','overs','over_no'])\n",
    "#df = pd.read_csv(\"final_all_3.1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = (spark.read.format(\"csv\").options(header=\"true\" , inferSchema = True).load(\"final_all_3.1.csv\"))\n",
    "\n",
    "#df = sqlContext.load(source=\"final_all_3.1.csv\", path = \"final_all_3.1.csv\", header = True,inferSchema = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- Unnamed: 0: integer (nullable = true)\n",
      " |-- Unnamed: 0.1: integer (nullable = true)\n",
      " |-- Unnamed: 0.1.1: integer (nullable = true)\n",
      " |-- batsman: string (nullable = true)\n",
      " |-- bowler: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- extras.byes: double (nullable = true)\n",
      " |-- extras.legbyes: double (nullable = true)\n",
      " |-- extras.noballs: double (nullable = true)\n",
      " |-- extras.penalty: double (nullable = true)\n",
      " |-- extras.s: double (nullable = true)\n",
      " |-- extras.wides: double (nullable = true)\n",
      " |-- index_all: integer (nullable = true)\n",
      " |-- non_striker: string (nullable = true)\n",
      " |-- replacements.match: string (nullable = true)\n",
      " |-- replacements.role: string (nullable = true)\n",
      " |-- runs.batsman: integer (nullable = true)\n",
      " |-- runs.extras: integer (nullable = true)\n",
      " |-- runs.non_boundary: double (nullable = true)\n",
      " |-- runs.total: integer (nullable = true)\n",
      " |-- team: string (nullable = true)\n",
      " |-- wicket: double (nullable = true)\n",
      " |-- wicket.fielders: string (nullable = true)\n",
      " |-- wicket.kind: string (nullable = true)\n",
      " |-- wicket.player_out: string (nullable = true)\n",
      " |-- info.bowl_out: string (nullable = true)\n",
      " |-- info.city: string (nullable = true)\n",
      " |-- info.competition: double (nullable = true)\n",
      " |-- info.dates: string (nullable = true)\n",
      " |-- info.gender: string (nullable = true)\n",
      " |-- info.match_type: string (nullable = true)\n",
      " |-- info.neutral_venue: double (nullable = true)\n",
      " |-- info.outcome.bowl_out: string (nullable = true)\n",
      " |-- info.outcome.by.innings: double (nullable = true)\n",
      " |-- info.outcome.by.runs: double (nullable = true)\n",
      " |-- info.outcome.by.wickets: double (nullable = true)\n",
      " |-- info.outcome.eliminator: string (nullable = true)\n",
      " |-- info.outcome.method: string (nullable = true)\n",
      " |-- info.outcome.result: string (nullable = true)\n",
      " |-- info.outcome.winner: string (nullable = true)\n",
      " |-- info.overs: integer (nullable = true)\n",
      " |-- info.player_of_match: string (nullable = true)\n",
      " |-- info.supersubs.Australia: string (nullable = true)\n",
      " |-- info.supersubs.Bangladesh: string (nullable = true)\n",
      " |-- info.supersubs.India: double (nullable = true)\n",
      " |-- info.supersubs.New Zealand: string (nullable = true)\n",
      " |-- info.supersubs.Pakistan: double (nullable = true)\n",
      " |-- info.supersubs.South Africa: string (nullable = true)\n",
      " |-- info.supersubs.Sri Lanka: string (nullable = true)\n",
      " |-- info.supersubs.West Indies: string (nullable = true)\n",
      " |-- info.teams: string (nullable = true)\n",
      " |-- info.toss.decision: string (nullable = true)\n",
      " |-- info.toss.winner: string (nullable = true)\n",
      " |-- info.umpires: string (nullable = true)\n",
      " |-- info.venue: string (nullable = true)\n",
      " |-- overs: string (nullable = true)\n",
      " |-- over_no: double (nullable = true)\n",
      "\n",
      "+---+----------+------------+--------------+---------+-------------+----------+-----------+--------------+--------------+--------------+--------+------------+---------+-----------+------------------+-----------------+------------+-----------+-----------------+----------+---------+------+---------------+-----------+-----------------+-------------+---------+----------------+----------+-----------+---------------+------------------+---------------------+-----------------------+--------------------+-----------------------+-----------------------+-------------------+-------------------+-------------------+----------+--------------------+------------------------+-------------------------+--------------------+--------------------------+-----------------------+---------------------------+------------------------+--------------------------+--------------------+------------------+----------------+--------------------+--------------------+-----+-------+\n",
      "|_c0|Unnamed: 0|Unnamed: 0.1|Unnamed: 0.1.1|  batsman|       bowler|      date|extras.byes|extras.legbyes|extras.noballs|extras.penalty|extras.s|extras.wides|index_all|non_striker|replacements.match|replacements.role|runs.batsman|runs.extras|runs.non_boundary|runs.total|     team|wicket|wicket.fielders|wicket.kind|wicket.player_out|info.bowl_out|info.city|info.competition|info.dates|info.gender|info.match_type|info.neutral_venue|info.outcome.bowl_out|info.outcome.by.innings|info.outcome.by.runs|info.outcome.by.wickets|info.outcome.eliminator|info.outcome.method|info.outcome.result|info.outcome.winner|info.overs|info.player_of_match|info.supersubs.Australia|info.supersubs.Bangladesh|info.supersubs.India|info.supersubs.New Zealand|info.supersubs.Pakistan|info.supersubs.South Africa|info.supersubs.Sri Lanka|info.supersubs.West Indies|          info.teams|info.toss.decision|info.toss.winner|        info.umpires|          info.venue|overs|over_no|\n",
      "+---+----------+------------+--------------+---------+-------------+----------+-----------+--------------+--------------+--------------+--------+------------+---------+-----------+------------------+-----------------+------------+-----------+-----------------+----------+---------+------+---------------+-----------+-----------------+-------------+---------+----------------+----------+-----------+---------------+------------------+---------------------+-----------------------+--------------------+-----------------------+-----------------------+-------------------+-------------------+-------------------+----------+--------------------+------------------------+-------------------------+--------------------+--------------------------+-----------------------+---------------------------+------------------------+--------------------------+--------------------+------------------+----------------+--------------------+--------------------+-----+-------+\n",
      "|  0|         0|           0|             0|DA Warner|Mohammad Amir|2017-01-13|        0.0|           0.0|           0.0|           0.0|     0.0|         0.0|        7|    TM Head|                 0|                0|           0|          0|              0.0|         0|Australia|   0.0|              0|          0|                0|            0| Brisbane|             0.0|2017-01-13|       male|            ODI|               0.0|                    0|                    0.0|                92.0|                    0.0|                      0|                  0|                  0|          Australia|        50|         ['MS Wade']|                       0|                        0|                 0.0|                         0|                    0.0|                          0|                       0|                         0|['Australia', 'Pa...|               bat|       Australia|['MD Martell', 'C...|Brisbane Cricket ...|  0.1|    1.0|\n",
      "|  1|         1|           1|             1|DA Warner|Mohammad Amir|2017-01-13|        0.0|           0.0|           0.0|           0.0|     0.0|         0.0|        7|    TM Head|                 0|                0|           0|          0|              0.0|         0|Australia|   0.0|              0|          0|                0|            0| Brisbane|             0.0|2017-01-13|       male|            ODI|               0.0|                    0|                    0.0|                92.0|                    0.0|                      0|                  0|                  0|          Australia|        50|         ['MS Wade']|                       0|                        0|                 0.0|                         0|                    0.0|                          0|                       0|                         0|['Australia', 'Pa...|               bat|       Australia|['MD Martell', 'C...|Brisbane Cricket ...|  0.2|    1.0|\n",
      "+---+----------+------------+--------------+---------+-------------+----------+-----------+--------------+--------------+--------------+--------+------------+---------+-----------+------------------+-----------------+------------+-----------+-----------------+----------+---------+------+---------------+-----------+-----------------+-------------+---------+----------------+----------+-----------+---------------+------------------+---------------------+-----------------------+--------------------+-----------------------+-----------------------+-------------------+-------------------+-------------------+----------+--------------------+------------------------+-------------------------+--------------------+--------------------------+-----------------------+---------------------------+------------------------+--------------------------+--------------------+------------------+----------------+--------------------+--------------------+-----+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data Frame Manipulations\n",
    "\n",
    "# To see datatype of columns\n",
    "df.printSchema()\n",
    "\n",
    "# Show first n observation\n",
    "df.head(5)\n",
    "# Or\n",
    "df.show(2,truncate= True)\n",
    "\n",
    "\n",
    "# To Count the number of rows in DataFrame\n",
    "df.count()\n",
    "\n",
    "# How many columns do we have in dataframes along with their names\n",
    "len(df.columns), df.columns\n",
    "\n",
    "# How to get the summary statistics (mean, standard deviance, min ,max , count) of numerical columns in a DataFrame\n",
    "        \n",
    "df.describe().show()\n",
    "train.describe('index_all').show()\n",
    "\n",
    "# To select column(s) from the DataFrame\n",
    "df.select('index_all','batsman').show(5)\n",
    "\n",
    "# To find the number of distinct index_all in dataframes\n",
    "train.select('index_all').distinct().count()\n",
    "\n",
    "#diff_cat_in_train_test=test.select('Product_ID').subtract(train.select('Product_ID'))\n",
    "#diff_cat_in_train_test.distinct().count()# For distict count\n",
    "\n",
    "\n",
    "#if I want to calculate pair wise frequency of categorical columns\n",
    "\n",
    "#train.crosstab('Age', 'Gender').show()\n",
    "#Output:\n",
    "#+----------+-----+------+\n",
    "#|Age_Gender|    F|     M|\n",
    "#+----------+-----+------+\n",
    "#|      0-17| 5083| 10019|\n",
    "#|     46-50|13199| 32502|\n",
    "#|     18-25|24628| 75032|\n",
    "#|     36-45|27170| 82843|\n",
    "#|       55+| 5083| 16421|\n",
    "#|     51-55| 9894| 28607|\n",
    "#|     26-35|50752|168835|\n",
    "#+----------+-----+------+\n",
    "\n",
    "# If I want to get the DataFrame which won’t have duplicate rows of given DataFrame\n",
    "df.select('index_all','batsman').dropDuplicates().show()\n",
    "\n",
    "# If I want to drop the all rows with null value\n",
    "df.dropna().count()\n",
    "\n",
    "#if I want to fill the null values in DataFrame with constant number\n",
    "df.fillna(-1).show(2)\n",
    "\n",
    "# If I want to filter the rows in df which has index_all more than 1000\n",
    "df.filter(df.index_all > 1000).count()\n",
    "\n",
    "# To find the mean of each batsman group in df\n",
    "df.groupby('batsman').agg({'runs': 'mean'}).show()\n",
    "\n",
    "df.groupby('batsman').count().show()\n",
    "\n",
    "# To create a sample DataFrame from the base DataFrame\n",
    "\n",
    "\n",
    "# withReplacement = True or False to select a observation with or without replacement.\n",
    "# fraction = x, where x = .5 shows that we want to have 50% data in sample DataFrame.\n",
    "# seed for reproduce the result\n",
    "\n",
    "d1 = df.sample(False, 0.2, 42)\n",
    "d2 = df.sample(False, 0.2, 43)\n",
    "d1.count(),d2.count()\n",
    "\n",
    "# To apply map operation on DataFrame columns\n",
    "df.select('index_all').map(lambda x:(x,1)).take(5)\n",
    "\n",
    "# to sort the DataFrame based on column(s)\n",
    "df.orderBy(df.index_all.desc()).show(5)\n",
    "\n",
    "# to add the new column in DataFrame\n",
    "df.withColumn('new_column', df.index_all /2.0).select('index_all','new_column').show(5)\n",
    "\n",
    "# to drop a column in DataFrame\n",
    "df.drop('`new.column`').columns\n",
    "\n",
    "# if I want to remove some categories of Product_ID column in test that are not present in Product_ID column in train\n",
    "#diff_cat_in_train_test=test.select('Product_ID').subtract(train.select('Product_ID'))\n",
    "#diff_cat_in_train_test.distinct().count()# For distict count\n",
    "#Output:\n",
    "#46\n",
    "\n",
    "# We have got 46 different categories in test. For removing these categories from the test ‘Product_ID’ column. I am applying these steps.\n",
    "\n",
    "#Create the distinct list of categories called ‘not_found_cat’ from the diff_cat_in_train_test using map operation.\n",
    "#Register a udf(user define function).\n",
    "#User defined function will take each element of test column and search this in not_found_cat list and it will put -1 if  it finds in this list otherwise it will do nothing.\n",
    "#Let’s see how it works. First create ‘not_found_cat’\n",
    "\n",
    "#not_found_cat = diff_cat_in_train_test.distinct().rdd.map(lambda x: x[0]).collect()\n",
    "#len(not_found_cat)\n",
    "#Output: \n",
    "#46\n",
    "\n",
    "#Now resister the udf, we need to import StringType from the pyspark.sql and udf from the pyspark.sql.functions. The udf function takes 2 parameters as arguments:\n",
    "\n",
    "#Function (I am using lambda function)\n",
    "#Return type (in my case StringType())\n",
    "\n",
    "#from pyspark.sql.types import StringType\n",
    "#from pyspark.sql.functions import udf\n",
    "#F1 = udf(lambda x: '-1' if x in not_found_cat else x, StringType())\n",
    "\n",
    "#In the above code function name is ‘F1’ and we are putting ‘-1’  \n",
    "#for not found catagories in test ‘Product_ID’. Finally apply above ‘F1’ function on test \n",
    "#‘Product_ID’ and take result in k1 for new column calles “NEW_Product_ID”.\n",
    "#k = test.withColumn(\"NEW_Product_ID\",F1(test[\"Product_ID\"])).select('NEW_Product_ID')\n",
    "\n",
    "# Now, let’s see the results by again calculating the different categories in k and train subtract operation.\n",
    "# diff_cat_in_train_test=k.select('NEW_Product_ID').subtract(train.select('Product_ID'))\n",
    "# diff_cat_in_train_test.distinct().count()# For distinct count\n",
    "# Output:\n",
    "# 1\n",
    "\n",
    "# The output 1 means we have now only 1 different category k and train.\n",
    "\n",
    "#diff_cat_in_train_test.distinct().collect()\n",
    "#Output:\n",
    "#Row(NEW_Product_ID=u'-1')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# To Apply SQL Queries on DataFrame\n",
    "\n",
    "df.registerAsTable('df_table')\n",
    "\n",
    "sqlContext.sql('select index_all from df_table').show(5)\n",
    "\n",
    "sqlContext.sql('select batsman, max(runs) from df_table group by batsman').show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
